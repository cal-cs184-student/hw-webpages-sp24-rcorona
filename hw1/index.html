<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184/284A Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184/284A: Computer Graphics and Imaging, Spring 2024</h1>
<h1 align="middle">Homework 1: Rasterizer</h1>
<h2 align="middle">Rodolfo Corona Rodriguez (3034203306) </h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>Give a high-level overview of what you implemented in this homework Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.</p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>
  
  <p>
  My algorithm uses a couple of helper functions, which I will describe first, I will then conclude with a high level overview of the algorithm.
  </p>
  <p><br>
  <p><b>Helper Functions:</b></p>
  <i>line_test</i>: This helper takes as input a pair of points ((x_0, y_0), (x_1, y_1)) defining a line and a third point (x,y) to serve as a query. 
  It performs a line test by first defining two vectors: <br>V = (x - x0, y - y0), i.e. the vector from the first line point to the query point, and 
  <br>N = (-(y1 - y0), x1 - x0), i.e. a vector perpendicular to the line. 
  Having defined these two vectors, the function returns the result of their dot product, which will be positive
  if the query point lies on the positive half-plane of the line, 0 if it lies directly on the line, or negative if it lies in the negative half-plane. 
  </p>
  <p>
  <i>inside</i>: Given three triangle points and a query point, this helper function determines if the query lies in the triangle. 
  As a first step, the function checks which direction denotes the inside of the triangle if we follow the vertex winding order of P0 --> P1, P1 --> P2, and P2 --> P0. 
  The direction is determined by performing a line test using P0 and P1 as the two line points and P2 as the query point. 
  If the direction line test is positive, then points in the triangle will lie on the positive half-plane of each triangle edge (or, conversely, on the negative half-plane if the line test is negative). 
  Therefore, a <i>direction</i> variable is set to +1 or -1 depending on the result of the direction line test. 
  Having determined the correct direction, the function then performs a line test for the query pixel on each edge (determined by each pair of triangle vertices) and multiplying it by the direction variable.
  If all line tests are >= 0 then that means the point lies on the correct side of each edge and the function returns True (and otherwise returnes False). 
  </p>
  <p>
  <b>High-level algorithm overview: </b> First, the algorithm determines the bounding box of the triangle by finding the maximum and minimum x and y coordinates in {x0, x1, x2} and {y0, y1, y2}. 
  Having determined the bounding box, a nested for loop (one for x and one for y coordinates) from the minimum (integer) x,y to the maximum in increments of 1 is traversed. 
  For each pair of (x,y) query points in the loop, the algorithm performs an <i>inside</i> test on the sample point (x + 0.5, y + 0.5) to determine if the point lies in the triangle or not.  
  If the sample point lies within the triangle then the pixel (x,y) is filled. 
  </p>
  <p>
  <b>Difficult Part:</b> I had the most trouble with making the algorithm robust to triangle vertex winding ordering. At first my algorithm assumed that all 3 line tests being non-negative 
  <i>always</i> means that a point lies in the triangle, however this is only true if P2 lies in the positive half-plane of the edge P0-->P1. If P2 lies on the negative half-plane 
  then the line tests must all be non-positive instead. Adding this check resolved the issue. 
  </p>
  <p>Below is a render of <i>basic/test4.svg</i> with the pixel inspector zoomed into the left corner of the red triangle. As may be observed, there is a discontinuity between some pixels on the tip of the corner and the rest of the triangle due to aliasing.</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task1_img.png" align="middle" width="400px"/>
        <figcaption align="middle">Render of <i>basic/test4.svg</i> with the pixel inspector zoomed into the left corner of the red triangle.</figcaption>
      </td>
    </tr>
  </table>
</div>

<h3 align="middle">Part 2: Antialiasing triangles</h3>
  
<p>
<b>Data Structures:</b> My algorithm primarily uses the <i>sample_buffer</i> to maintain a super-sampled image during rasterization, the size of this buffer will be the (width * height * sample_rate). <br>
  Additionally, I maintain a <i>sqrt_sample_rate</i> variable which is only computed once per sample rate change such that we don't have to perform a sqrt operation each time we need it. 
</p>

<p>
<b>Algorithm Walkthrough</b>: When rasterizing a triangle, the algorithm first scales the coordinates of the triangle by <i>sqrt_sample_rate</i> in order to get it at the scale of the now super-sampled sample buffer.<br>
  Following this, rasterization of the triangle follows as usual, with the rasterizer looping over the pixels in the bounding box of the (now scaled) triangle. <br>
  After all the triangles are rasterized and <i>resolve_to_frame_buffer</i> is called, the algorithm will compute the color value of each frame buffer pixel by averaging the values of all sample_buffer locations pertaining to that pixel.<br>
  During frame buffer resolution process, the sample buffer coordinates for pixel (x,y) will be ((j * width * sqrt_sample_rate), (y * width * sample_rate)) for i,j in [0, sqrt_sample_rate]. 
</p>

  <p>
  <b>Why is super-sampling useful?:</b> Super-sampling is useful because it scales the sampling frequency by sqrt_sample_rate in each axis, reducing aliasing. <br>
    Increasing the sample frequency combats aliasing because it raises the Nyquist frequency (the rate which signal frequencies must stay below in order to avoid aliasing) for the signal, which is going to be half the sample rate. <br>
    In other words, because we are increasing the frequency of the samples, we are able to capture faster ocurring changes in the image. 
  </p>
  <p>
  <b>What modifications did I make?:</b> Firstly, the sample buffer data structure was dynamically updated to be able to fit the appropriate number of samples. <br>
    In both the <i>set_sample_rate</i> and <i>set_framebuffer_target</i> methods the sample buffer is resized to (width * height * sample_rate) to accomodate the samples. <br>
    The <i>fill_pixel</i> method was modified to access the sample buffer at the (y * width * sqrt_sample_rate + x) location in order to accomodate the scaled coordinates. <br>
    Lastly, the <i>rasterize_triangle</i> and <i>resolve_to_frame_buffer</i> methods were modified as described above. 
  </p>
  <p>
  Below is a side-by-side comparison of sample rates of 1, 4, and 16 with the pixel inspecto zoomed over the left corner of the red triangle in <i>basic/test4.svg</i>.<br>

  </p>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task2_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Sampling rate of 1.</figcaption>
      </td>
      <td>
        <img src="images/task2_4.png" align="middle" width="400px"/>
        <figcaption align="middle">Sampling rate of 4.</figcaption>
      </td>
      <td>
        <img src="images/task2_16.png" align="middle" width="400px"/>
        <figcaption align="middle">Sampling rate of 16.</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
  As may be observed, the corner becomes smoother as the sampling rate increases. <br>
  To have a smoother image, the ideal color (assuming there is only one triangle + the background in a pixel) would be the color of the triangle weighted by the proportion of the pixel which the triangle is filling. <br>
  However, solving this analyitically would be much more expensive, and so samples are taken to approximate this proportion. <br>
  Higher sampling rates yield better approximations of the true proportion, and thus higher sample rates yield smoother images with less aliasing. 
</p>

<h3 align="middle">Part 3: Transforms</h3>

  <p>
For my cubeman version, I wanted to have cubeman look like they were jumping and raising their hands up in the air.<br>
To accomplish this, the legs were rotated by 45 degrees each and translated a little higher to get the look right. <br>
Similarly, the arms were rotated by 90 degrees and translated up to look like they were being raised up all the way.<br>
Lastly, the legs were colored blue and the arms were colored green. 
</p>
    
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task3_myrobot.png" align="middle" width="400px"/>
        <figcaption align="middle">Cubeman jumping and raising their hands up in the air.</figcaption>
      </td>
    </tr>
  </table>
</div>

<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>

Barycentric coordinates are the coordinates for a point in relation to the vertices of a triangle. <br>
Each of the three coordinates, (alpha, beta, gamma), represent the relative weight the proximity of each vertex has to a given query point. 
In other words, the barycentric coordinates represent the spatial weighted sum of the three vertices which would result in the coordinates 
of the query point. <br>
Because these weights vary smoothly, as one moves the query point across the triangle, then these same weights can be used to smoothly interpolate
any other value (e.g. color, surface normals, etc.) across the triangle. 
For example, the image below uses barycentric coordinates to smoothly interpolate the color values of a red, green, and blue cornered triangle across the
body of the triangle. 

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task4_interp_triangle.png" align="middle" width="400px"/>
        <figcaption align="middle">Cubeman jumping and raising their hands up in the air.</figcaption>
      </td>
    </tr>
  </table>
</div>

Additionally, here is an image of a full color gradient wheel rasterized using barycentric coordinate interpolation. 

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task4_gradient.png" align="middle" width="400px"/>
        <figcaption align="middle">Cubeman jumping and raising their hands up in the air.</figcaption>
      </td>
    </tr>
  </table>
</div>
  
<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>

  <p>
<b>Pixel Sampling Definition:</b> Pixel sampling from textures is the process through which color samples from an image, known as the texture, are mapped to screen space during the rasterization process. <br>
  To do this, a bijective function is defined which maps from coordinates in screen space (or coordinates in a mesh) to coordinates within the texture image (referred to as the (u,v) coordinates of the point). <br>
  The rate of change of this mapping function need not be constant, i.e. du/dx, du/dy, dv/dx, and dv/dy are not necessarily constant across screen space. <br>
    Coordinates (u,v) lie in the continuous range [0,1], and thus when converting to discrete texel coordinates in the texture image, they must be scaled by the width and height of the texture image and then discretized into an integer coordinate. 
  </p>
<p>
  <b>Implementation: The rasterization algorithm is nearly identical to the prior two triangle rasterization methods, differing only in what is done once a sample point is determined to be inside the triangle. <br>
    If a point is inside the triangle, I first compute the barycentric coordinates for that point, and use the barycentric coordinate weights to compute the sample point's (u,v) coordinates as a weighted sum of the (u,v) coordinates of the triangle vertices. <br>
    Having computed the sample point's (u,v) coordinates, the algorithm then samples a color value using one of the two sampling methods described below. 
</p>
  <p>
    <b>Sampling Method Descriptions:</b> For each of the two sampling methods below, the sample point's continuous texel coordinates are first computed: (tx, ty) = (u * texture_width, v * texture_height). <br>
    These continuos texel coordinates are then used by each of the two sampling methods as described below. 
  </p>
  <p>
    <i>Nearest Neighbor Sampling:</i> Given a continuous texel coordinate (tx, ty), nearest neighbor sampling returns the texel (texture image pixel) pertaining to the nearest discrete coordinate in the texture image. <br>
    Assuming that sampling is performed based on distance to texel center (i.e. the distance to each texel is computed from (tx + 0.5, ty + 0.5)) <br>
    then the nearest discrete texel coordinate for a continuous (tx,ty) is going to be the floor of each of those two values, i.e. (floor(tx), floor(ty)). 
  </p>
  <p>
    <i>Bilinear Sampling:</i> Bilinear sampling computes the returned texture sample as the weighted average of the four nearest texels to a given (tx,ty) coordinate (with the weights being proportional to the distance from it). <br>
      The appropriate interpolation can be performed by a sequence of three lerp (linear interpolation) operations. <br>
      First, the two texels in each row (where each row contains two of the four nearest texels to the sample point) are linearly interpolated into intermediate color values proportionally to their horizontal distance from the sample (tx,ty) point. <br>
      Next, the two intermediate values are linearly interpolated into a final value proprtionally to their vertical distance from the sample (tx,ty) point. <br>
      The result of this third lerp is what is returned as the texture sample.  
  </p>

<p>
  <b>Comparison:</b> Below we can see a comparison between both sampling methods using sampling rates of 1 and 16. <br>
  The comparison is using the image of the campanille and has the pixel inspector focused on the face of the campanielle where there are many arches. 
</p>
      
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task5_nearest_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Neighbor, Sampling Rate of 1</figcaption>
      </td>
      <td>
        <img src="images/task5_nearest_16.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Neighbor, Sampling Rate of 16</figcaption>
      </td>
    </tr>
    <tr>
      <td>
        <img src="images/task5_bilinear_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear, Sampling Rate of 1</figcaption>
      </td>
      <td>
        <img src="images/task5_bilinear_16.png" align="middle" width="400px"/>
        <figcaption align="middle">Bilinear, Sampling Rate of 16</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
Two things can be clearly observed from the pixel inspector region. Firstly, notice how in the <i>nearest</i> case with sampling rate of 1 there are much larger jumps in color/intensity values across pixels. <br>
In contrast, using the bilinear sampling method results in smoother and more gradual transitions in color across the pixels in the region. <br>
Similarly, one can notice that the same is true for both methods as the sampling rate is increased from 1 to 16.
</p>
<p>
<b>Relative Differences:</b> The two methods differ mainly in terms of their efficiency and effectiveness. Nearest neighbor sampling is cheaper since only a single texel needs to be queried, as opposed to 4 in the bilinear sampling case which <br>
  additionally must incur the cost of three lerp operations per pixel sample. If the sampling rate in the image is close to being in sync with the sampling rate in the texture (i.e. one pixel transition in the image also corresponds to one texel transition in the texture), <br>
 then the nearest neighbor method is likely sufficient since there will be little aliasing. <br>
However, if the image is magnified or minified (i.e. the sampling rate in the image is either larger or smaller than that of the texture), then there will be aliasing and/or sharp discontinuities in the intensity transitions between sampled values. <br>
  Because bilinear interpolation performs a weighted sum between the closest 4 texels proportional to their distance from the sample, this will alleviate problems in both magnification and in minification. <br>
  For magnification it will allow for a smooth transition between texel samples, avoiding sharp changes, and in the minification case it will reduce aliasing since it effectively doubles the sampling frequency in the texture. 
</p>
<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>

<p>
  <b>Level Sampling Discussion:</b> To avoid aliasing in the rasterized image, the sampling rate in the image is ideally in sync with the sampling rate in the texture, i.e. moving one pixel in the image corresponds to one texel move in the texture. <br>
  Unfortunately, the rate of change of pixels to texels is not always one, and also may dynamically vary across the image, in some places being higher or lower than 1. <br>
  Level sampling combats the case when the rate of change is higher than 1 by precomputing an image pyramid (in this case known as a mipmap) of varying downsampled resolutions of the texture. <br>
  Precomputing the downsamples effectively lowers the frequency of each image in the mipmap by a rate of 1/2, where a level x pertains to a rate of change of 2^x in terms of how many texels are traversed per pixel change <br>
  (e.g. if every pixel change pertains to two texels, then the ideal mipmap level is log(2) == 1). <br>
  By precomputing the downsampled textures and then dynamically selecting texel samples per pixel based on the current rate of change in the image allows for anti-aliasing in the rasterized image.
</p>
  <p>
    <b>Implementation:</b> For the implementation, the mipmap was already precomputed, so only the implementation of dynamic level selection was required. <br>
    To compute the level for a given pixel, the uv coordinates of that pixel as well as the pixel to the right and the pixel below are computed (these pixels are pixels in the image <i>before</i> super sampling, ie. (x + sqrt_sample_rate, y + sqrt_sample_rate). <br>
    These values are computed within <i>rasterize_textured_triangle</i> and used to populate a <i>SampleParams</i> struct.
  </p>
  <p>
    Within the <i>get_level</i> method, the rate of change from pixels to texels is computed for each axis by first taking the difference between the sample (u,v) coordinates and the (u,v) coordinates of the pixel on the right and the pixel below. <br>
    These differences are scaled by the width and height of the texture in order to arrive at a rate of change in the space of texels. <br>
    The log of the max of the norms of the two difference vectors is taken to arrive at an approximate ideal level for the pixel sample. <br>
    Before taking the log, edge cases are handled by setting the level to 0 if the max of the norms is < 1.0 (i.e. log would return a negative) or by 
      clipping the level to the last level if the computed level value is higher than that. 
  </p>
  <p>
    <b>Tradeoffs:</b> 
  </p>
    <p>
      <i>Memory:</i> For an image of dimensions (W,H) and texture image of dimensions (WT, HT) the base amount of memory storage required is (W * H) + (WT * HT)<br>
      Increasing the sampling rate by value S will result in image memory requirement of (S * W * H), i.e. scale it by S, in order to accomodate the new sample buffer. <br>
      Using level sampling will increase the memory requirement by approximately 1/3 * (WT * HT), since the downsampled mipmap levels can effectively be stored in memory the size of one of the RGB channels of the full size texture. <br>
      Changing the pixel sampling strategy will not heavily impact memory requirements since the only additional overhead required is the intermediate storage of 4 color values in the case of bilinear sampling, but that is done per pixel sample and does not persist in memory. 
    </p>
      <p>
      <i>Speed:</i> For speed there is a base compute cost of O(W * H), since the number of operations will scale with the image size. <br>
        Similarly to memory, increasing the sampling rate scales the compute cost by S since all of the operations are repeated for all all sampled pixels, i.e O(S * W * H) <br>
        Level sampling adds a constant amount of compute cost to each sample's operations, since the number of operations needed per sample does not depend on the image nor on the texture dimensions. <br>
        Bilinear level sampling adds an additional constant cost to computations that does not scale with image nor texture dimensions (roughly, it doubles a subset of operations). 
        Therefore level sampling results in a cost of O(W * H + (W * H) O(1)) == O(W * H). <br>
        Changing the pixel sampling strategy also adds a constant cost to the computation, with bilinear pixel sampling being more expensive than nearest neighbor (4x some subset of operations) but still scaling by a constant amount that does not depend on the image nor texture dimensions.
      </p>
      <p>
        <i>Anti-aliasing Power:</i> Increasing the sampling rate effectively doubles the sampling frequency in each axis, also doubling the Nyquist frequency and therefore doubling the maximum frequency that can be represented in the image before aliasing occurs. <br>
        Level sampling dynamically selects a level of downsampling/averaging in the texture image per sampled image pixel, which effectively allows it to lower the frequency of the texture image by as much as a factor log_2(max_level). 
        because the 0th level represents a sampling rate of 1, level sampling only helps treat alliasing resulting from texture sampling rates higher than 1, not lower (i.e. it helps with minification, not magnification).<br>
        Bilinear pixel sampling allows for smooth transitions between texels, which I believe is particularly helpful for cases of magnification, where the sampling rate in the texture is less than 1 texel. 
        Nearest neighbor pixel sampling does not anti-alias. <br>
      </p>
      <p>
        <b>Overall assessment:</b> Overall it appears that mipmap level sampling with bilinear pixel sampling likely has the best tradeoff between memory/compute costs and anti-aliasing power since it allows for dynamic texture frequency sampling while only adding a <br>
        constant cost to computation and memory. Super-sampling if raised high enough will have the strongest anti-aliasing effect but will also incur the greatest computational costs. 
      </p>

      <p>
      Below is an example of fractal image under different combinations of level sampling and pixel sampling strategies. 
        </p>
      <div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/task6_zero_nearest.png" align="middle" width="400px"/>
        <figcaption align="middle">Zero Level, Nearest Pixel</figcaption>
      </td>
      <td>
        <img src="images/task6_zero_linear.png" align="middle" width="400px"/>
        <figcaption align="middle">Zero Level, Bilinear Pixel</figcaption>
      </td>
    </tr>
    <tr>
      <td>
        <img src="images/task6_nearest_nearest.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Level, Nearest Pixel</figcaption>
      </td>
      <td>
        <img src="images/task6_nearest_linear.png" align="middle" width="400px"/>
        <figcaption align="middle">Nearest Level, Bilinear Pixel</figcaption>
      </td>
    </tr>
  </table>
</div>
As may be observed, using the zero level and nearest pixel strategies results in a more aliased image. From zooming into the center with the pixel inspector, we can see that there are much
larger jumps in pixel intensities/colors. <br>
Interestingly, at least for the center of the image, it appears that zero-level with bilinear pixel and nearest-level with nearest-pixel achieve the best tradeoff between anti-aliasing and maintaining key details in the pattern. <br>
The nearest-level with bilinear pixel sampling strategy results in the smoothest transitions in the image but unfortunately washes out some of the detail in the center. 

<h2 align="middle">Section III: Art Competition</h2>
<p>If you are not participating in the optional art competition, don't worry about this section!</p>

<h3 align="middle">Part 7: Draw something interesting!</h3>

</body>
</html>
